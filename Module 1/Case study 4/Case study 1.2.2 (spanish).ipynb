{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Caso-de-estudio-1.2.2:-Agrupamiento-espectral:-Agrupación-de-noticias\" data-toc-modified-id=\"Caso-de-estudio-1.2.2:-Agrupamiento-espectral:-Agrupación-de-noticias-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Caso de estudio 1.2.2: Agrupamiento espectral: Agrupación de noticias</a></span></li><li><span><a href=\"#Generación-de-la-base-de-datos-(Web-Scraping)\" data-toc-modified-id=\"Generación-de-la-base-de-datos-(Web-Scraping)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Generación de la base de datos (Web Scraping)</a></span></li><li><span><a href=\"#Importación-de-la-base-de-datos\" data-toc-modified-id=\"Importación-de-la-base-de-datos-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Importación de la base de datos</a></span></li><li><span><a href=\"#Generación-de-atributos\" data-toc-modified-id=\"Generación-de-atributos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Generación de atributos</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso de estudio 1.2.2: Agrupamiento espectral: Agrupación de noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<br>\n",
    "\n",
    "Este caso de estudio considera una base de datos de artículos de prensa, sobre diferentes temas, y usa _clusterización espectral_ para agruparlos dependiendo de la frecuencia de ciertas palabras. Este notebook proporciona el código para generar la base de datos, pero también puede enocontrar un ejemplo de base de datos en la carpeta `/Data`. Esta base de datos se generó el día 8 de junio de 2020 mediante técnicas de minería de datos (_web scraping_).\n",
    "\n",
    "Este caso de estudio usa la librería [`mitie`](https://github.com/mit-nlp/MITIE), desarrollada en MIT. Todos los pasos para instalar tnato la librería como el modelo NER usado en este caso de estudio pueden encontrarse en la documentación online.\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuración del notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:14:10.864777Z",
     "start_time": "2020-06-08T23:14:08.386716Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading NER model...\n",
      "\n",
      "Tags output by this NER model: ['PERSON', 'LOCATION', 'ORGANIZATION', 'MISC']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "\n",
    "#ML\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import cluster\n",
    "\n",
    "#Web scraping libraries\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#NLP libraries\n",
    "from mitie import *\n",
    "#Para poder correr este notebook has de descargar el modelo NER de mitie\n",
    "print(\"loading NER model...\")\n",
    "#ner = named_entity_extractor('MITIE-models/english/ner_model.dat')\n",
    "ner = named_entity_extractor('/Users/inigo/opt/anaconda3/lib/python3.7/site-packages/mitie/models/MITIE-models/english/ner_model.dat')\n",
    "print(\"\\nTags output by this NER model:\", ner.get_possible_ner_tags())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de la base de datos (Web Scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, artículos de 8 temas diferentes del periódico __The Guardian__ han sido recopilados. Los pasos a seguir para crear la base de datos son:\n",
    "\n",
    "1. Obtener el código fuente de la web principal de The Guardian, y almacenar los links a las secciones (temas) de interés.\n",
    "2. Iterar la lista de links y obtener la información de 10 artículos por sección (título y contenido).\n",
    "3. Guardar los artículos, títulos, y temas en archivos `.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:14:11.530709Z",
     "start_time": "2020-06-08T23:14:10.866851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: Elections_2020 (https://www.theguardian.com/us-news/us-elections-2020)\n",
      "Topic 2: World (https://www.theguardian.com/world)\n",
      "Topic 3: Environment (https://www.theguardian.com/us/environment)\n",
      "Topic 4: Soccer (https://www.theguardian.com/football)\n",
      "Topic 5: US_Politics (https://www.theguardian.com/us-news/us-politics)\n",
      "Topic 6: Business (https://www.theguardian.com/us/business)\n",
      "Topic 7: Tech (https://www.theguardian.com/us/technology)\n",
      "Topic 8: Science (https://www.theguardian.com/science)\n"
     ]
    }
   ],
   "source": [
    "UK_news_url = 'https://www.theguardian.com/uk'\n",
    "#Descargando los links de los diferentes temas\n",
    "html_data = requests.get(UK_news_url).text\n",
    "soup = BeautifulSoup(html_data, 'html.parser')\n",
    "url_topics = [el.find('a')['href'] for el in soup.find_all(class_ = 'subnav__item')[1:9]]\n",
    "topics = [el.text.strip('\\n').replace(' ','_') for el in soup.find_all(class_ = 'subnav-link')[1:9]]\n",
    "for i in range(len(topics)):\n",
    "    print('Topic {}: {} ({})'.format(i+1,topics[i],url_topics[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:14:54.791725Z",
     "start_time": "2020-06-08T23:14:11.533015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elections_2020:\n",
      "Joe Biden officially clinches Democratic presidential nomination\n",
      "Joe Biden says '10-15%' of Americans 'are just not very good people'\n",
      "Democrats unveil ambitious plan for police reform: 'This is a first step'\n",
      "Trump tried to vote with wrong address while railing against voter fraud\n",
      "Trump and Biden offer starkly different visions with nation at a crossroads\n",
      "America's seniors ebb away from Trump as coronavirus response disappoints\n",
      "‘It could have a chilling effect’: why Trump is ramping up attacks on mail-in voting\n",
      "‘The United States is broken as hell’ – the division in politics over race and class\n",
      "Socialism used to be a dirty word. Is America now ready to embrace it?\n",
      "'Nothing to lose': how Trump has energized America's women\n",
      "Article count: 10\n",
      "\n",
      "World:\n",
      "New York cautiously starts to reopen for business after coronavirus lockdown\n",
      "Matt Hancock hails coronavirus 'retreat' as UK deaths tumble\n",
      "Workers in Tokyo's red-light district to be tested for coronavirus after new spike\n",
      "Prince Andrew in war of words with US prosecutors over Epstein\n",
      "UK diplomats fear end of special relationship if Trump re-elected\n",
      "Trump move to take US troops out of Germany 'a dangerous game'\n",
      "US has officially entered first recession since 2009\n",
      "Labour's left uneasy with leader's view on tearing down Colston statue\n",
      "Sweden to present findings on Olof Palme assassination\n",
      "Alarm at Turkish plan to expand powers of nightwatchmen\n",
      "Article count: 20\n",
      "\n",
      "Environment:\n",
      "$1m treasure in Rocky Mountains has been found, says Forrest Fenn\n",
      "Louisiana: coastal residents evacuated as Tropical Storm Cristobal approaches\n",
      "Trump orders agencies cut environment reviews, citing 'economic emergency'\n",
      "Court overturns EPA approval of popular herbicide made by Monsanto\n",
      "US ranks 24th in the world on environmental performance\n",
      "Renewables surpass coal in US energy generation for first time in 130 years\n",
      "Firms ignoring climate crisis will go bankrupt, says Mark Carney\n",
      "Walking app helps tree lovers know their sycamores from their maples\n",
      "Many of the 300 plants and animals endemic to Canada at risk, report finds\n",
      "'Selling off the future’: Trump allows fishing in marine monument\n",
      "Article count: 30\n",
      "\n",
      "Soccer:\n",
      "Billy Kee: 'If I didn’t opt out of football, I don’t know if I would be alive'\n",
      "Tony Dunne, Manchester United European Cup winner, dies aged 78\n",
      "League One row breaks out as teams get tested and train before key vote\n",
      "Merseyside derby in limbo after safety group postpones Goodison decision\n",
      "Bayern remind Leverkusen of just where they sit in the pecking order\n",
      "Premier League restart preview No 2: Aston Villa\n",
      "Premier League restart preview No 1: Arsenal\n",
      "My favourite game: when Denmark beat Uruguay 6-1 at the 86 World Cup\n",
      "Pep Clotet to step down as Birmingham manager at end of season\n",
      "Football quiz: surprise domestic Cup finalists\n",
      "Article count: 40\n",
      "\n",
      "US_Politics:\n",
      "‘Apathy is no longer a choice’: will the George Floyd protests energize young voters?\n",
      "‘They set us up’: US police arrested over 10,000 protesters, many non-violent\n",
      "Minneapolis lawmakers vow to disband police department in historic move\n",
      "Racism in America is not the exception – it's the norm\n",
      "Trump's use of the military backfired – but will it back him if he refuses to go?\n",
      "Tennessee voters must be allowed to vote safely – by mail – this November\n",
      "America's top cop is a rightwing culture warrior who hates disorder. What could go wrong?\n",
      "A week that shook a nation: anger burns as power of protests leaves Trump exposed\n",
      "Iowa touted its Covid-19 testing. Now officials are calling for an investigation\n",
      "'As guarded as Fort Knox': the inside story of Hillary Clinton's presidential campaign\n",
      "Article count: 50\n",
      "\n",
      "Business:\n",
      "Facebook moderators join criticism of Zuckerberg over Trump stance\n",
      "BP to cut 10,000 jobs worldwide amid huge drop in demand for oil\n",
      "World Bank warns Covid-19 pandemic risks dramatic rise in poverty\n",
      "Covid-19 vaccine: AstraZeneca has 'approached Gilead over possible merger'\n",
      "Opec and allies extend oil production cuts to end of July\n",
      "The Fed deserves the praise for America’s jobs turnaround. But Trump benefits\n",
      "Angela Merkel has become the spend, spend, spend chancellor\n",
      "Coronavirus solves one problem for US employers: finding workers\n",
      "Europe’s big two kiss and make up for pandemic rescue deal\n",
      "England could suspend Sunday trading laws in push to boost economy\n",
      "Article count: 60\n",
      "\n",
      "Tech:\n",
      "Smart appliances may not be worth money in long run, warns Which?\n",
      "Zoom to exclude free calls from end-to-end encryption to allow FBI cooperation\n",
      "Embarrassing teenage posts on Facebook? Now you can delete them\n",
      "More than 140 Zuckerberg-funded scientists call on Facebook to rein in Trump\n",
      "Zuckerberg: Facebook will review policies after backlash over Trump posts\n",
      "Zoom booms as teleconferencing company profits from coronavirus crisis\n",
      "Hackers targeting UK research labs amid vaccine race – GCHQ chief\n",
      "New vulnerability allows users to 'jailbreak' iPhones\n",
      "Huge rise in hacking attacks on home workers during lockdown\n",
      "Fraud, fine food and old tights\n",
      "Article count: 70\n",
      "\n",
      "Science:\n",
      "Gardens of the galaxy: can you grow vegetables on Mars?\n",
      "We can no longer ignore the potential of psychedelic drugs to treat depression\n",
      "Starwatch: how to find the Great Diamond in the sky\n",
      "We often accuse the right of distorting science. But the left changed the coronavirus narrative overnight\n",
      "After six months of coronavirus, how close are we to defeating it?\n",
      "The first wave of Covid-19 is not over – but how might a second look?\n",
      "Hydroxychloroquine and coronavirus: a guide to the scientific studies so far\n",
      "UK minister hails 'game-changing' coronavirus immunity test\n",
      "UK ministers face legal challenge for refusal to order PPE inquiry\n",
      "People who think they have had Covid-19 ‘less likely to download contact-tracing app’\n",
      "Article count: 80\n"
     ]
    }
   ],
   "source": [
    "def save_to_txt(filename, content):\n",
    "    '''\n",
    "    Creates a new .txt file with as specific name in the Data directory\n",
    "    '''\n",
    "    with open(r\"Data/{}.txt\".format(filename), \"w\") as f:\n",
    "        print(content, file=f)\n",
    "\n",
    "article_titles = []\n",
    "article_contents = []\n",
    "article_topics = []\n",
    "articles_per_topic = 10\n",
    "n = 1\n",
    "for topic, url_topic in list(zip(topics,url_topics)):\n",
    "    #Getting the first 15\n",
    "    soup = BeautifulSoup(requests.get(url_topic).text, 'html.parser')\n",
    "    url_articles = [el.find('a')['href'] for el in soup.find_all(class_ = 'fc-item__content')]\n",
    "    print('\\n{}:'.format(topic))\n",
    "    i = 0\n",
    "    while article_topics.count(topic) < articles_per_topic:\n",
    "        soup = BeautifulSoup(requests.get(url_articles[i]).text, 'html.parser')\n",
    "        try:\n",
    "            title = soup.find(class_ = 'content__headline').text.strip('\\n')\n",
    "            content = ' '.join([el.text for el in soup.find(class_ = 'content__article-body from-content-api js-article__body').find_all('p')])\n",
    "            i += 1\n",
    "            if i == len(url_articles):\n",
    "                print('Only {} articles found in \\\"{}\"'.format(article_topics.count(topic),topic))\n",
    "                break\n",
    "            if title not in article_titles:\n",
    "                article_titles += [title]\n",
    "                article_contents += [content]\n",
    "                article_topics += [topic]\n",
    "                save_to_txt('title-{}'.format(n),title)\n",
    "                save_to_txt('article-{}'.format(n),content)\n",
    "                save_to_txt('topic-{}'.format(n),topic)\n",
    "                print('{}'.format(title))\n",
    "                n += 1\n",
    "                if round(len(article_titles)/10) == len(article_titles)/10:\n",
    "                    print('Article count: {}'.format(len(article_titles)))\n",
    "        except:\n",
    "            i += 1\n",
    "            if i == len(url_articles):\n",
    "                print('Only {} articles found in \\\"{}\"'.format(article_topics.count(topic),topic))\n",
    "                break\n",
    "            pass\n",
    "        \n",
    "                \n",
    "df = pd.DataFrame({'topic':article_topics,'title':article_titles,'content':article_contents})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos la base de datos guardada en carpeta deseada, podemos usar el código del caso de estudio para importar la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:14:54.827485Z",
     "start_time": "2020-06-08T23:14:54.793892Z"
    }
   },
   "outputs": [],
   "source": [
    "#número total de artículos para procesar.\n",
    "N = 80\n",
    "#para almacenar los temas, títulos y contenidos de las noticias:\n",
    "topics_array = []\n",
    "titles_array = []\n",
    "corpus = []\n",
    "for i in range(1, N+1):\n",
    "    #consiga el contenido del artículo.\n",
    "    with open('Data/article-' + str(i) + '.txt', 'r') as myfile:\n",
    "        d1=myfile.read().replace('\\n', '')\n",
    "        d1 = d1.lower()\n",
    "        corpus.append(d1)\n",
    "    #consiga el tema original del artículo.\n",
    "    with open('Data/topic-' + str(i) + '.txt', 'r') as myfile:\n",
    "        to1=myfile.read().replace('\\n', '')\n",
    "        to1 = to1.lower()\n",
    "        topics_array.append(to1)\n",
    "    #consiga el título del artículo.\n",
    "    with open('Data/title-' + str(i) + '.txt', 'r') as myfile:\n",
    "        ti1=myfile.read().replace('\\n', '')\n",
    "        ti1 = ti1.lower()\n",
    "        titles_array.append(ti1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar los atributos de cada instancia (artículo):\n",
    "\n",
    "1. Enlazamos todos los corpus de texto de artículos para determinar todas las palabras únicas que se utilizan en el conjunto de datos.\n",
    "2. Buscamos el subconjunto de las entidades del modelo NER que se encuentra entre las palabras únicas que se utilizan en el conjunto de datos (determinado en el paso 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:33:56.085401Z",
     "start_time": "2020-06-08T23:33:54.892765Z"
    }
   },
   "outputs": [],
   "source": [
    "#vector de subconjunto de entidades\n",
    "entity_text_array = [] \n",
    "for i in range(1, N+1):\n",
    "    #cargue el archivo de texto con el contenido del artículo y conviértalo en una lista de palabras\n",
    "    tokens = tokenize(load_entire_file(('Data/article-' + str(i) + '.txt')))\n",
    "    #extraiga todas las entidades conocidas del modelo ner mencionado en este artículo\n",
    "    entities = ner.extract_entities(tokens)\n",
    "    #extraiga las palabras de entidades reales y agréguelas al vector\n",
    "    for e in entities: \n",
    "        range_array = e[0]\n",
    "        tag = e[1]\n",
    "        score = e[2]\n",
    "        score_text = \"{:0.3f}\".format(score)\n",
    "        entity_text = \" \".join(tokens[j].decode(\"utf-8\") for j in range_array) \n",
    "        entity_text_array.append(entity_text.lower())\n",
    "#elimine las entidades duplicadas que se hayan detectado\n",
    "#entity_text_array = np.unique(entity_text_array)\n",
    "entity_text_array = list(set(entity_text_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-22T19:12:49.108073Z",
     "start_time": "2020-05-22T19:12:49.094235Z"
    }
   },
   "source": [
    "Ahora que ya tenemos la lista de todas las entidades utilizadas en la base de datos, podemos representar cada artículo como un vector que contiene la puntuación de [TF-IDF](https://en.wikipedia.org/wiki/Tf–idf) para cada entidad almacenada en el `entity_text_array`. Esta tarea se puede realizar fácilmente con la librería [scikit-learn](http://scikit- learn.org/stable/) de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:14:56.146658Z",
     "start_time": "2020-06-08T23:14:56.098058Z"
    }
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(sublinear_tf=True, max_df=0.5, analyzer='word',\n",
    "                       stop_words='english', vocabulary=entity_text_array)\n",
    "corpus_tf_idf = vect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos los artículos representados por sus atributos (puntuaciones de TF-IDF), podemos llevar a cabo el agrupamiento espectral de los mismos usando la librería `scikit-learn` de nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:14:56.211117Z",
     "start_time": "2020-06-08T23:14:56.148577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpectralClustering(affinity='nearest_neighbors', assign_labels='kmeans',\n",
       "                   coef0=1, degree=3, eigen_solver='arpack', eigen_tol=0.0,\n",
       "                   gamma=1.0, kernel_params=None, n_clusters=8,\n",
       "                   n_components=None, n_init=10, n_jobs=None, n_neighbors=10,\n",
       "                   random_state=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change n_clusters to equal the number of clusters desired\n",
    "n_clusters = 8\n",
    "#spectral clustering\n",
    "spectral = cluster.SpectralClustering(n_clusters= n_clusters, \n",
    "                                      eigen_solver='arpack', \n",
    "                                      affinity=\"nearest_neighbors\", \n",
    "                                      n_neighbors = 10)\n",
    "spectral.fit(corpus_tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente las siguientes líneas de código permiten ver el output en el siguiente formato (una línea por artículo):\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>__no. artículo, tema, cluster, título__</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:14:56.228444Z",
     "start_time": "2020-06-08T23:14:56.215438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 elections_2020 2 joe biden officially clinches democratic presidential nomination\n",
      "1 elections_2020 2 joe biden says '10-15%' of americans 'are just not very good people'\n",
      "2 elections_2020 6 democrats unveil ambitious plan for police reform: 'this is a first step'\n",
      "3 elections_2020 2 trump tried to vote with wrong address while railing against voter fraud\n",
      "4 elections_2020 2 trump and biden offer starkly different visions with nation at a crossroads\n",
      "5 elections_2020 2 america's seniors ebb away from trump as coronavirus response disappoints\n",
      "6 elections_2020 2 ‘it could have a chilling effect’: why trump is ramping up attacks on mail-in voting\n",
      "7 elections_2020 2 ‘the united states is broken as hell’ – the division in politics over race and class\n",
      "8 elections_2020 2 socialism used to be a dirty word. is america now ready to embrace it?\n",
      "9 elections_2020 2 'nothing to lose': how trump has energized america's women\n",
      "10 world 6 new york cautiously starts to reopen for business after coronavirus lockdown\n",
      "11 world 1 matt hancock hails coronavirus 'retreat' as uk deaths tumble\n",
      "12 world 6 workers in tokyo's red-light district to be tested for coronavirus after new spike\n",
      "13 world 2 prince andrew in war of words with us prosecutors over epstein\n",
      "14 world 7 uk diplomats fear end of special relationship if trump re-elected\n",
      "15 world 7 trump move to take us troops out of germany 'a dangerous game'\n",
      "16 world 7 us has officially entered first recession since 2009\n",
      "17 world 5 labour's left uneasy with leader's view on tearing down colston statue\n",
      "18 world 2 sweden to present findings on olof palme assassination\n",
      "19 world 0 alarm at turkish plan to expand powers of nightwatchmen\n",
      "20 environment 7 $1m treasure in rocky mountains has been found, says forrest fenn\n",
      "21 environment 1 louisiana: coastal residents evacuated as tropical storm cristobal approaches\n",
      "22 environment 2 trump orders agencies cut environment reviews, citing 'economic emergency'\n",
      "23 environment 2 court overturns epa approval of popular herbicide made by monsanto\n",
      "24 environment 7 us ranks 24th in the world on environmental performance\n",
      "25 environment 2 renewables surpass coal in us energy generation for first time in 130 years\n",
      "26 environment 5 firms ignoring climate crisis will go bankrupt, says mark carney\n",
      "27 environment 0 walking app helps tree lovers know their sycamores from their maples\n",
      "28 environment 2 many of the 300 plants and animals endemic to canada at risk, report finds\n",
      "29 environment 2 'selling off the future’: trump allows fishing in marine monument\n",
      "30 soccer 3 billy kee: 'if i didn’t opt out of football, i don’t know if i would be alive'\n",
      "31 soccer 4 tony dunne, manchester united european cup winner, dies aged 78\n",
      "32 soccer 1 league one row breaks out as teams get tested and train before key vote\n",
      "33 soccer 4 merseyside derby in limbo after safety group postpones goodison decision\n",
      "34 soccer 4 bayern remind leverkusen of just where they sit in the pecking order\n",
      "35 soccer 4 premier league restart preview no 2: aston villa\n",
      "36 soccer 4 premier league restart preview no 1: arsenal\n",
      "37 soccer 1 my favourite game: when denmark beat uruguay 6-1 at the 86 world cup\n",
      "38 soccer 1 pep clotet to step down as birmingham manager at end of season\n",
      "39 soccer 2 football quiz: surprise domestic cup finalists\n",
      "40 us_politics 2 ‘apathy is no longer a choice’: will the george floyd protests energize young voters?\n",
      "41 us_politics 6 ‘they set us up’: us police arrested over 10,000 protesters, many non-violent\n",
      "42 us_politics 6 minneapolis lawmakers vow to disband police department in historic move\n",
      "43 us_politics 2 racism in america is not the exception – it's the norm\n",
      "44 us_politics 2 trump's use of the military backfired – but will it back him if he refuses to go?\n",
      "45 us_politics 6 tennessee voters must be allowed to vote safely – by mail – this november\n",
      "46 us_politics 2 america's top cop is a rightwing culture warrior who hates disorder. what could go wrong?\n",
      "47 us_politics 2 a week that shook a nation: anger burns as power of protests leaves trump exposed\n",
      "48 us_politics 1 iowa touted its covid-19 testing. now officials are calling for an investigation\n",
      "49 us_politics 2 'as guarded as fort knox': the inside story of hillary clinton's presidential campaign\n",
      "50 business 3 facebook moderators join criticism of zuckerberg over trump stance\n",
      "51 business 1 bp to cut 10,000 jobs worldwide amid huge drop in demand for oil\n",
      "52 business 5 world bank warns covid-19 pandemic risks dramatic rise in poverty\n",
      "53 business 0 covid-19 vaccine: astrazeneca has 'approached gilead over possible merger'\n",
      "54 business 7 opec and allies extend oil production cuts to end of july\n",
      "55 business 3 the fed deserves the praise for america’s jobs turnaround. but trump benefits\n",
      "56 business 7 angela merkel has become the spend, spend, spend chancellor\n",
      "57 business 5 coronavirus solves one problem for us employers: finding workers\n",
      "58 business 7 europe’s big two kiss and make up for pandemic rescue deal\n",
      "59 business 5 england could suspend sunday trading laws in push to boost economy\n",
      "60 tech 1 smart appliances may not be worth money in long run, warns which?\n",
      "61 tech 0 zoom to exclude free calls from end-to-end encryption to allow fbi cooperation\n",
      "62 tech 3 embarrassing teenage posts on facebook? now you can delete them\n",
      "63 tech 3 more than 140 zuckerberg-funded scientists call on facebook to rein in trump\n",
      "64 tech 3 zuckerberg: facebook will review policies after backlash over trump posts\n",
      "65 tech 0 zoom booms as teleconferencing company profits from coronavirus crisis\n",
      "66 tech 7 hackers targeting uk research labs amid vaccine race – gchq chief\n",
      "67 tech 0 new vulnerability allows users to 'jailbreak' iphones\n",
      "68 tech 7 huge rise in hacking attacks on home workers during lockdown\n",
      "69 tech 5 fraud, fine food and old tights\n",
      "70 science 7 gardens of the galaxy: can you grow vegetables on mars?\n",
      "71 science 6 we can no longer ignore the potential of psychedelic drugs to treat depression\n",
      "72 science 6 starwatch: how to find the great diamond in the sky\n",
      "73 science 6 we often accuse the right of distorting science. but the left changed the coronavirus narrative overnight\n",
      "74 science 6 after six months of coronavirus, how close are we to defeating it?\n",
      "75 science 1 the first wave of covid-19 is not over – but how might a second look?\n",
      "76 science 7 hydroxychloroquine and coronavirus: a guide to the scientific studies so far\n",
      "77 science 1 uk minister hails 'game-changing' coronavirus immunity test\n",
      "78 science 1 uk ministers face legal challenge for refusal to order ppe inquiry\n",
      "79 science 1 people who think they have had covid-19 ‘less likely to download contact-tracing app’\n"
     ]
    }
   ],
   "source": [
    "if hasattr(spectral, 'labels_'):\n",
    "    cluster_assignments = spectral.labels_.astype(np.int)\n",
    "    for i in range(0, len(cluster_assignments)):\n",
    "        print (i, topics_array[i], cluster_assignments [i], titles_array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:32:21.170169Z",
     "start_time": "2020-06-08T23:32:21.154055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions_0</th>\n",
       "      <th>predictions_1</th>\n",
       "      <th>predictions_2</th>\n",
       "      <th>predictions_3</th>\n",
       "      <th>predictions_4</th>\n",
       "      <th>predictions_5</th>\n",
       "      <th>predictions_6</th>\n",
       "      <th>predictions_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Business</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elections_2020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Environment</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soccer</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tech</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US_Politics</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>World</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predictions_0  predictions_1  predictions_2  predictions_3  \\\n",
       "topic                                                                        \n",
       "Business                    1              1              0              2   \n",
       "Elections_2020              0              0              9              0   \n",
       "Environment                 1              1              5              0   \n",
       "Science                     0              4              0              0   \n",
       "Soccer                      0              3              1              1   \n",
       "Tech                        3              1              0              3   \n",
       "US_Politics                 0              1              6              0   \n",
       "World                       1              1              2              0   \n",
       "\n",
       "                predictions_4  predictions_5  predictions_6  predictions_7  \n",
       "topic                                                                       \n",
       "Business                    0              3              0              3  \n",
       "Elections_2020              0              0              1              0  \n",
       "Environment                 0              1              0              2  \n",
       "Science                     0              0              4              2  \n",
       "Soccer                      5              0              0              0  \n",
       "Tech                        0              1              0              2  \n",
       "US_Politics                 0              0              3              0  \n",
       "World                       0              1              2              3  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['predictions'] = cluster_assignments\n",
    "predictions_df = pd.get_dummies(df, columns=['predictions']).drop(['title','content'],axis=1).groupby(['topic']).sum()\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede observarse, el algoritmo no clasifica los artículos según las secciones de las que se han obtenido. Puede indagar más a fondo en los parámetros del modelo para mejorar dichos resultados, o buscar una explicación para entender el criterio con el que el algoritmo está agrupando los artículos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Created by Iñigo de la Maza. Contact: [idelamaza.com](https://idelamaza.github.io/)\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-08T23:14:56.682563Z",
     "start_time": "2020-06-08T23:14:56.269163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of packages and versions:\n",
      "\n",
      "scikit-learn==0.22.1\n",
      "requests==2.23.0\n",
      "pandas==1.0.0\n",
      "numpy==1.18.1\n",
      "mitie==0.7.36\n",
      "matplotlib==3.1.3\n",
      "beautifulsoup4==4.9.1\n"
     ]
    }
   ],
   "source": [
    "## IGNORE THE CODE BELOW ##\n",
    "\n",
    "#Getting names of imported libraries and versions for creating a requirements.txt file\n",
    "import pkg_resources\n",
    "import types\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "            \n",
    "        poorly_named_packages = {\n",
    "            \"PIL\": \"Pillow\",\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "            \n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "requirements.append(('beautifulsoup4', '4.9.1'))    \n",
    "#Getting the packages already included in requirements.txt\n",
    "with open(r\"../../requirements.txt\", \"r\") as f:\n",
    "    pkgs = [pkg.split('==')[0] for pkg in f.readlines()]\n",
    "#Adding missing packages\n",
    "print('List of packages and versions:\\n')     \n",
    "with open(r\"../../requirements.txt\", \"a\") as f:\n",
    "    for r in requirements:\n",
    "        print(\"{}=={}\".format(*r))\n",
    "        if r[0] not in pkgs:\n",
    "            f.write(\"{}=={}\\n\".format(*r))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.545px",
    "left": "938.091px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
